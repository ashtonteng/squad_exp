{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from utils import DataLoader\n",
    "import re\n",
    "import numpy as np\n",
    "working_dir = os.getcwd()\n",
    "data_dir = os.path.join(working_dir, \"data\")\n",
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 100\n",
    "batch_size = 10\n",
    "rnn_size = 50\n",
    "W_inputs = tf.constant(np.random.random((rnn_size, rnn_size)), dtype=\"float32\")\n",
    "W_pointerRNN = tf.constant(np.random.random((rnn_size, rnn_size)), dtype=\"float32\")\n",
    "v = tf.constant(np.random.random((rnn_size, 1)), dtype=\"float32\")\n",
    "W_inputs_tiled = tf.tile(tf.expand_dims(W_inputs, 0), [batch_size, 1, 1])\n",
    "#W_pointerRNN_tiled = tf.tile(tf.expand_dims(W_pointerRNN, 0), [batch_size, 1, 1])\n",
    "v_tiled = tf.tile(tf.expand_dims(v, 0), [batch_size, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((batch_size, max_seq_length, rnn_size)), dtype=\"float32\")\n",
    "def compute_lengths(inputs):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(inputs), reduction_indices=2))\n",
    "    lengths = tf.reduce_sum(used, reduction_indices=1)\n",
    "    lengths = tf.cast(lengths, tf.int32) #lengths must be integers\n",
    "    return lengths\n",
    "seq_lengths = compute_lengths(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: use attention-pooling over the question representation for the initialize hidden vector of pointer network\n",
    "def loop_fn(time, prev_output, prev_state, prev_loop_state):\n",
    "    print('start loop', time)\n",
    "    next_output = prev_output\n",
    "    if prev_output is None:\n",
    "        next_state = cell.zero_state(batch_size, tf.float32)\n",
    "    else:\n",
    "        next_state = prev_state\n",
    "    next_loop_state = None\n",
    "    def get_next_input():\n",
    "        print(\"computing logits\")\n",
    "        print(\"prev_output\", prev_output)\n",
    "        if prev_output is None:\n",
    "            logits = tf.matmul(tf.tanh(tf.matmul(inputs, W_inputs_tiled)), v_tiled) #batch_size x seq_length x rnn_size\n",
    "        else:\n",
    "            print(\"i have prev output now\")\n",
    "            logits = tf.matmul(\n",
    "                             tf.tanh(tf.matmul(inputs, W_inputs_tiled) + \n",
    "                                     tf.tile(tf.expand_dims(tf.matmul(prev_output, W_pointerRNN), 1), [1, max_seq_length, 1]))\n",
    "                             , v_tiled) #batch_size x seq_length x rnn_size\n",
    "        print(\"computing probs\")\n",
    "        predicted_probs = tf.nn.softmax(logits, dim=1) #a\n",
    "        print(\"predicted_probs\")\n",
    "        weighted_input = tf.reduce_sum(tf.multiply(predicted_probs, inputs), axis=1) #c #batch_size x rnn_size\n",
    "        print(\"returning weighted_input\")\n",
    "        return weighted_input #weighted input is next input\n",
    "    print(\"1\")\n",
    "    elements_finished = (time >= seq_lengths) #this operation produces boolean tensor of [batch_size] defining if corresponding sequence has ended\n",
    "    print(\"2\")\n",
    "    finished = tf.reduce_all(elements_finished) #AND operation over all batches. True if all batches finished.\n",
    "    time += 1\n",
    "    print(\"3\")\n",
    "    next_input = tf.cond(finished, lambda: tf.zeros([batch_size, rnn_size], dtype=tf.float32), get_next_input)\n",
    "    print(\"4\")\n",
    "    return elements_finished, next_input, next_state, next_output, next_loop_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loop Tensor(\"rnn/Const:0\", shape=(), dtype=int32)\n",
      "1\n",
      "2\n",
      "3\n",
      "computing logits\n",
      "prev_output None\n",
      "computing probs\n",
      "predicted_probs\n",
      "returning weighted_input\n",
      "4\n",
      "start loop Tensor(\"rnn/while/add:0\", shape=(), dtype=int32)\n",
      "1\n",
      "2\n",
      "3\n",
      "computing logits\n",
      "prev_output Tensor(\"rnn/while/lstm_cell/mul_2:0\", shape=(10, 50), dtype=float32)\n",
      "i have prev output now\n",
      "computing probs\n",
      "predicted_probs\n",
      "returning weighted_input\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
    "    cell = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "    outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "    outputs = outputs_ta.stack()\n",
    "    #predicted_idx = tf.argmax(predicted_probs) #p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape_2:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 10, 50]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((batch_size, max_seq_length, rnn_size)), dtype=\"float32\")\n",
    "inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_seq_length)\n",
    "inputs_ta = inputs_ta.unstack(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ta.size().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ta.read(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((max_seq_length, batch_size, rnn_size)), dtype=\"float32\")\n",
    "inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_seq_length)\n",
    "inputs_ta = inputs_ta.unstack(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ta.read(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.LSTMCell(rnn_size, reuse=True)\n",
    "outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "outputs = outputs_ta.stack()\n",
    "outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "outputs = outputs_ta.stack()\n",
    "predicted_idx = tf.argmax(self.predicted_probs) #p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: use attention-pooling over the question representation for the initialize hidden vector of pointer network\n",
    "def loop_fn(time, prev_output, prev_state, prev_loop_state):\n",
    "    print('start loop')\n",
    "    next_output = prev_output\n",
    "    if prev_output is None:\n",
    "        next_cell_state = cell.zero_state(batch_size, tf.float32)\n",
    "    else:\n",
    "        next_cell_state = prev_state\n",
    "    next_loop_state = None\n",
    "    def get_next_input():\n",
    "        print(\"computing logits\")\n",
    "        print(inputs_ta.read(time))\n",
    "        print(prev_output)\n",
    "        if prev_output is None:\n",
    "            logits = tf.matmul(v, tf.tanh(tf.matmul(inputs_ta.read(time), W_inputs)))\n",
    "        else:\n",
    "            logits = tf.matmul(tf.tanh(tf.matmul(inputs_ta.read(time), W_inputs) + tf.matmul(prev_output, W_pointerRNN)), v) #s #at each step network has access to all paragraph inputs, plus the previous RNN outputs\n",
    "        print(\"computing probs\")\n",
    "        predicted_probs = tf.nn.softmax(logits) #a\n",
    "        print(\"computing weighted_input\")\n",
    "        weighted_input = tf.reduce_sum(tf.multiply(predicted_probs, inputs)) #c\n",
    "        return weighted_input #weighted input is next input\n",
    "    print(\"1\")\n",
    "    elements_finished = (time >= seq_lengths) #this operation produces boolean tensor of [batch_size] defining if corresponding sequence has ended\n",
    "    print(\"2\")\n",
    "    finished = tf.reduce_all(elements_finished) #AND operation over all batches. True if all batches finished.\n",
    "    time += 1\n",
    "    print(\"3\")\n",
    "    next_input = tf.cond(finished, lambda: tf.zeros([batch_size, rnn_size], dtype=tf.float32), get_next_input)\n",
    "    print(\"4\")\n",
    "    return elements_finished, next_input, next_state, next_output, next_loop_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((batch_size, max_seq_length, rnn_size)))\n",
    "def compute_lengths(inputs):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(inputs), reduction_indices=2))\n",
    "    lengths = tf.reduce_sum(used, reduction_indices=1)\n",
    "    lengths = tf.cast(lengths, tf.int32) #lengths must be integers\n",
    "    return lengths\n",
    "seq_lengths = compute_lengths(inputs)\n",
    "seq_lengths.eval()\n",
    "def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "    print(\"start loop\")\n",
    "    emit_output = cell_output  # == None for time == 0\n",
    "    if cell_output is None:  # time == 0\n",
    "        next_cell_state = cell.zero_state(batch_size, tf.float32)\n",
    "    else:\n",
    "        next_cell_state = cell_state\n",
    "    print(\"1\")\n",
    "    elements_finished = (time >= seq_lengths)\n",
    "    print(\"2\")\n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "    print(\"3\")\n",
    "    next_input = tf.cond(\n",
    "        finished,\n",
    "        lambda: tf.zeros([batch_size, rnn_size], dtype=tf.float32),\n",
    "        lambda: inputs_ta.read(time))\n",
    "    print(\"4\")\n",
    "    next_loop_state = None\n",
    "    print(\"5\")\n",
    "    print(\"elements_finished\", elements_finished)\n",
    "    print(\"next_input\", next_input)\n",
    "    print(\"next_cell_state\", next_cell_state)\n",
    "    print(\"next_loop_state\", next_loop_state)\n",
    "    return elements_finished, next_input, next_cell_state, emit_output, next_loop_state\n",
    "\n",
    "max_seq_length = 100\n",
    "batch_size = 10\n",
    "rnn_size = 50\n",
    "W_inputs = tf.constant(np.random.random((rnn_size, rnn_size)))\n",
    "W_pointerRNN = tf.constant(np.random.random((rnn_size, rnn_size)))\n",
    "v = tf.constant(np.random.random((1, rnn_size)))\n",
    "inputs = tf.constant(np.random.random((max_seq_length, batch_size, rnn_size)))\n",
    "inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_seq_length)\n",
    "inputs_ta = inputs_ta.unstack(inputs)\n",
    "cell = tf.contrib.rnn.LSTMCell(rnn_size, reuse=True)\n",
    "outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "outputs = outputs_ta.stack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
