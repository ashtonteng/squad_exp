{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from utils import DataLoader\n",
    "import re\n",
    "import numpy as np\n",
    "working_dir = os.getcwd()\n",
    "data_dir = os.path.join(working_dir, \"data\")\n",
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocab files...\n",
      "loading preprocessed data...\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(data_dir=data_dir, embedding_dim=100, batch_size=20, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_loader.load_json_data(os.path.join(data_loader.squad_dir, \"train-v1.1.json\"))[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict, para_to_qa_dict, qa_data_dict, discarded_dict = data_loader.parse_json_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "['start', 'value', 'of', 'a', 'routine', 'is', 'based', 'on', 'the', 'difficulty', 'of', 'the', 'elements', 'the', 'gymnast', 'attempts', 'and', 'whether', 'or', 'not', 'the', 'gymnast', 'meets', 'composition', 'requirements']\n",
      "['e', 'start', 'value', 'of', 'a', 'routine', 'is', 'based', 'on', 'the', 'difficulty', 'of', 'the', 'elements', 'the', 'gymnast', 'attempts', 'and', 'whether', 'or', 'not', 'the', 'gymnast', 'meets', 'composition', 'requirements']\n",
      "---\n",
      "---\n",
      "['.', 'the', 'resulting', 'indo', '-', 'scythian', 'kingdom', 'seems', 'to', 'have', 'gradually', 'pushed', 'the', 'remaining', 'indo', '-', 'greek']\n",
      "['dom', '.', 'the', 'resulting', 'indo', '-', 'scythian', 'kingdom', 'seems', 'to', 'have', 'gradually', 'pushed', 'the', 'remaining', 'indo', '-', 'greek']\n",
      "---\n",
      "---\n",
      "['zealander']\n",
      "['new', 'zealand']\n",
      "---\n",
      "---\n",
      "['known']\n",
      "['kno']\n",
      "---\n",
      "---\n",
      "['millionth']\n",
      "['hundred', 'million']\n",
      "---\n",
      "---\n",
      "['highest']\n",
      "['228']\n",
      "---\n",
      "---\n",
      "['government']\n",
      "['28', 'july', '180']\n",
      "---\n",
      "---\n",
      "['went']\n",
      "['25']\n",
      "---\n",
      "---\n",
      "['bilaterally']\n",
      "['bilateral']\n",
      "---\n",
      "---\n",
      "['non']\n",
      "['no']\n",
      "---\n",
      "---\n",
      "['five']\n",
      "['5']\n",
      "---\n",
      "---\n",
      "['s']\n",
      "['ks']\n",
      "---\n",
      "---\n",
      "['uniformity']\n",
      "['uniform']\n",
      "---\n",
      "---\n",
      "['foxes']\n",
      "['fox']\n",
      "---\n",
      "---\n",
      "['been']\n",
      "['b']\n",
      "---\n",
      "---\n",
      "['international', 'airlines', 'and', 'increasing', 'numbers', 'of', 'airlines', 'have', 'began', 'launching', 'direct', 'flights', 'from', 'japan', ',', 'qatar', ',', 'taiwan', ',', 'south', 'korea', ',', 'germany', 'and', 'singapore', '.']\n",
      "['5', 'international', 'airlines', 'and', 'increasing', 'numbers', 'of', 'airlines', 'have', 'began', 'launching', 'direct', 'flights', 'from', 'japan', ',', 'qatar', ',', 'taiwan', ',', 'south', 'korea', ',', 'germany', 'and', 'singapore', '.']\n",
      "---\n",
      "---\n",
      "['fourteenth']\n",
      "['fourteen']\n",
      "---\n",
      "---\n",
      "['incans']\n",
      "['inca']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['of']\n",
      "['often', 'scripted', 'to', 'dispense', 'with', 'the', 'appearance', 'of', 'neutrality', 'and', 'use', 'their', 'influence', 'to', 'unfairly', 'influence', 'the', 'outcome', 'of', 'the', 'match', 'for', 'added', 'dramatic', 'impact', '.', 'f']\n",
      "---\n",
      "---\n",
      "['located', '15', 'km', 'southwest', 'of', 'dushanbe']\n",
      "['t', 'located', '15', 'km', 'southwest', 'of', 'dushanbe']\n",
      "---\n",
      "---\n",
      "['european']\n",
      "['continental', 'europe']\n",
      "---\n",
      "---\n",
      "['kyōto京都']\n",
      "['kyōto']\n",
      "---\n",
      "---\n",
      "['parks', ',', 'schools', ',', 'public', 'buildings', ',', 'proper', 'roads', 'and', 'the', 'other', 'amenities', 'that', 'characterise', 'a', 'modern', 'city']\n",
      "['t', 'parks', ',', 'schools', ',', 'public', 'buildings', ',', 'proper', 'roads', 'and', 'the', 'other', 'amenities', 'that', 'characterise', 'a', 'modern', 'city']\n",
      "---\n",
      "---\n",
      "['japanese']\n",
      "['japan']\n",
      "---\n",
      "---\n",
      "['science', '-', 'fiction', 'and', 'adventure']\n",
      "['y', 'science', '-', 'fiction', 'and', 'adventure']\n",
      "---\n",
      "---\n",
      "['ser']\n",
      "['sere']\n",
      "---\n",
      "---\n",
      "['the']\n",
      "['tes', '(', '3']\n",
      "---\n",
      "---\n",
      "['northern']\n",
      "['north']\n",
      "---\n",
      "---\n",
      "['on']\n",
      "['1']\n",
      "---\n",
      "---\n",
      "['enriched']\n",
      "['enrich']\n",
      "---\n",
      "---\n",
      "['ce']\n",
      "['5th', 'ce']\n",
      "---\n",
      "---\n",
      "['%', 'of', 'public', 'spending', ',', '38', '%', 'for', 'the', 'regional', 'governments', ',', '13', '%', 'for', 'the', 'local', 'councils', ',', 'and', 'the', 'remaining', '31', '%', 'for', 'the', 'social', 'security', 'system']\n",
      "['8', '%', 'of', 'public', 'spending', ',', '38', '%', 'for', 'the', 'regional', 'governments', ',', '13', '%', 'for', 'the', 'local', 'councils', ',', 'and', 'the', 'remaining', '31', '%', 'for', 'the', 'social', 'security', 'system']\n",
      "---\n",
      "---\n",
      "['eight']\n",
      "['8']\n",
      "---\n",
      "---\n",
      "['and']\n",
      "['ano']\n",
      "---\n",
      "---\n",
      "['five']\n",
      "['5']\n",
      "---\n",
      "---\n",
      "['breeds']\n",
      "['breed']\n",
      "---\n",
      "---\n",
      "['one']\n",
      "['1']\n",
      "---\n",
      "---\n",
      "['four']\n",
      "['4']\n",
      "---\n",
      "---\n",
      "['nine']\n",
      "['9']\n",
      "---\n",
      "---\n",
      "['aircraft']\n",
      "['50s']\n",
      "---\n",
      "---\n",
      "['million']\n",
      "['1', 'million']\n",
      "---\n",
      "---\n",
      "['standard']\n",
      "['dard']\n",
      "---\n",
      "---\n",
      "['word', 'slovo', '(', '\"', 'word', '\"', ')', 'and', 'the', 'related', 'slava', '(', '\"', 'fame', '\"', ')', 'and', 'slukh', '(', '\"', 'hearing', '\"', ')']\n",
      "['he', 'word', 'slovo', '(', '\"', 'word', '\"', ')', 'and', 'the', 'related', 'slava', '(', '\"', 'fame', '\"', ')', 'and', 'slukh', '(', '\"', 'hearing', '\"', ')']\n",
      "---\n",
      "---\n",
      "['claude', 'r', '.', 'kirk', ',', 'jr', '.', 'was', 'elected', 'as', 'the', 'first', 'post', '-', 'reconstruction', 'republican', 'governor', ',', 'in', 'an', 'upset', 'election']\n",
      "['966', 'claude', 'r', '.', 'kirk', ',', 'jr', '.', 'was', 'elected', 'as', 'the', 'first', 'post', '-', 'reconstruction', 'republican', 'governor', ',', 'in', 'an', 'upset', 'election']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['heart']\n",
      "['30s']\n",
      "---\n",
      "---\n",
      "['tournament']\n",
      "['14']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['wings', 'of', 'flightless', 'birds', 'and', 'the', 'rudiments', 'of', 'pelvis', 'and', 'leg', 'bones', 'found', 'in', 'some', 'snakes']\n",
      "['e', 'wings', 'of', 'flightless', 'birds', 'and', 'the', 'rudiments', 'of', 'pelvis', 'and', 'leg', 'bones', 'found', 'in', 'some', 'snakes']\n",
      "---\n",
      "---\n",
      "['not']\n",
      "['ano']\n",
      "---\n",
      "---\n",
      "['electronic', 'dance', 'music', 'and', 'hip', 'hop', 'releases', 'today', 'are', 'still', 'preferred', 'on', 'vinyl']\n",
      "['any', 'electronic', 'dance', 'music', 'and', 'hip', 'hop', 'releases', 'today', 'are', 'still', 'preferred', 'on', 'vinyl']\n",
      "---\n",
      "---\n",
      "['around', 'it']\n",
      "['rld', 'around', 'it']\n",
      "---\n",
      "---\n",
      "['manually']\n",
      "['manual']\n",
      "---\n",
      "---\n",
      "['allows', 'information', 'from', 'the', 'outside', 'world', 'to', 'be', 'sensed', 'in', 'the', 'form', 'of', 'chemical', 'and', 'physical', 'stimuli', '.']\n",
      "['g', 'allows', 'information', 'from', 'the', 'outside', 'world', 'to', 'be', 'sensed', 'in', 'the', 'form', 'of', 'chemical', 'and', 'physical', 'stimuli', '.']\n",
      "---\n",
      "---\n",
      "['eight']\n",
      "['8']\n",
      "---\n",
      "---\n",
      "['basses']\n",
      "['drone', 'bass']\n",
      "---\n",
      "---\n",
      "['a']\n",
      "['pro', '-', 'christian', 'kachin', 'independence', 'army', 'a']\n",
      "---\n",
      "---\n",
      "['six']\n",
      "['6']\n",
      "---\n",
      "---\n",
      "['hunting']\n",
      "['hunt']\n",
      "---\n",
      "---\n",
      "['regional']\n",
      "['region']\n",
      "---\n",
      "---\n",
      "['river']\n",
      "['v']\n",
      "---\n",
      "---\n",
      "['intuitively']\n",
      "['intuitive']\n",
      "---\n",
      "---\n",
      "['in']\n",
      "['soviet', 'union', 'i']\n",
      "---\n",
      "---\n",
      "['thousandth']\n",
      "['thousand']\n",
      "---\n",
      "---\n",
      "['of', 'which', 'was', 'paid', 'by', 'cambridge', 'university', 'press', ',', '200', 'by', 'the', 'royal', 'society', 'of', 'london', ',', 'and', '50', 'apiece', 'by', 'whitehead', 'and', 'russell']\n",
      "['00', 'of', 'which', 'was', 'paid', 'by', 'cambridge', 'university', 'press', ',', '200', 'by', 'the', 'royal', 'society', 'of', 'london', ',', 'and', '50', 'apiece', 'by', 'whitehead', 'and', 'russell']\n",
      "---\n",
      "---\n",
      "['localizing']\n",
      "['local']\n",
      "---\n",
      "---\n",
      "['seven']\n",
      "['7']\n",
      "---\n",
      "---\n",
      "['greek']\n",
      "['the', 'gre']\n",
      "---\n",
      "---\n",
      "['bohmann']\n",
      "['joseph', 'bohm']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['avoiding']\n",
      "['avoid']\n",
      "---\n",
      "---\n",
      "['in', 'the', 'united', 'states', 'is', 'the', 'evolving', 'relationship', 'between', 'state', 'governments', 'and', 'the', 'federal', 'government', 'of', 'the', 'united', 'states']\n",
      "['ederalism', 'in', 'the', 'united', 'states', 'is', 'the', 'evolving', 'relationship', 'between', 'state', 'governments', 'and', 'the', 'federal', 'government', 'of', 'the', 'united', 'states']\n",
      "---\n",
      "---\n",
      "['notes']\n",
      "['no']\n",
      "---\n",
      "---\n",
      "['fourth']\n",
      "['4']\n",
      "---\n",
      "---\n",
      "['fourth']\n",
      "['twenty', '-', 'four']\n",
      "---\n",
      "---\n",
      "['which']\n",
      "['263']\n",
      "---\n",
      "---\n",
      "['several']\n",
      "['75']\n",
      "---\n",
      "---\n",
      "['as']\n",
      "['the', 'affected', 's']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['single']\n",
      "['sing']\n",
      "---\n",
      "---\n",
      "['dashes']\n",
      "['blue', 'dash']\n",
      "---\n",
      "---\n",
      "['of']\n",
      "['y', 'of']\n",
      "---\n",
      "---\n",
      "['fifteenth']\n",
      "['15']\n",
      "---\n",
      "---\n",
      "['one']\n",
      "['1']\n",
      "---\n",
      "---\n",
      "['extremely']\n",
      "['extreme']\n",
      "---\n",
      "---\n",
      "['buddhism']\n",
      "['buddh']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['semi', '-', 'finals', 'have', 'been', 'played', 'exclusively', 'at', 'the', 'rebuilt', 'wembley', 'stadium']\n",
      "['e', 'semi', '-', 'finals', 'have', 'been', 'played', 'exclusively', 'at', 'the', 'rebuilt', 'wembley', 'stadium']\n",
      "---\n",
      "---\n",
      "['more']\n",
      "['1']\n",
      "---\n",
      "---\n",
      "['following']\n",
      "['41']\n",
      "---\n",
      "---\n",
      "['their']\n",
      "['32']\n",
      "---\n",
      "---\n",
      "['to']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['drosis']\n",
      "['greek', 'artists', 'include', 'renaissance', 'painter', 'dominikos', 'theotokopoulos', '(', 'el', 'greco', ')', ',', 'panagiotis', 'do']\n",
      "---\n",
      "---\n",
      "['consulship']\n",
      "['consul']\n",
      "---\n",
      "---\n",
      "['harpist']\n",
      "['harp']\n",
      "---\n",
      "---\n",
      "['edward', 'j', '.', 'gurney', ',', 'also', 'a', 'white', 'conservative', ',', 'was', 'elected', 'as', 'the', 'state', \"'\", 's', 'first', 'post', '-', 'reconstruction', 'republican', 'us', 'senator']\n",
      "['968', 'edward', 'j', '.', 'gurney', ',', 'also', 'a', 'white', 'conservative', ',', 'was', 'elected', 'as', 'the', 'state', \"'\", 's', 'first', 'post', '-', 'reconstruction', 'republican', 'us', 'senator']\n",
      "---\n",
      "---\n",
      "['golfer']\n",
      "['golf']\n",
      "---\n",
      "---\n",
      "['europe']\n",
      "['western', 'europe']\n",
      "---\n",
      "---\n",
      "['seven']\n",
      "['7']\n",
      "---\n",
      "---\n",
      "['peacefully']\n",
      "['peaceful']\n",
      "---\n",
      "---\n",
      "['consultancy']\n",
      "['the', 'current', 'chairman', 'is', 'sir', 'dave', 'richards', ',', 'who', 'was', 'appointed', 'in', 'april', '199']\n",
      "---\n",
      "---\n",
      "['negatively']\n",
      "['negative']\n",
      "---\n",
      "---\n",
      "['representative']\n",
      "['december', '6', ',', '195']\n",
      "---\n",
      "---\n",
      "['million', 'years', 'ago']\n",
      "['40', 'million', 'years', 'ago']\n",
      "---\n",
      "---\n",
      "['emotional']\n",
      "['emotion']\n",
      "---\n",
      "---\n",
      "['notes']\n",
      "['no']\n",
      "---\n",
      "---\n",
      "['for']\n",
      "['four']\n",
      "---\n",
      "---\n",
      "['operatic']\n",
      "['opera']\n",
      "---\n",
      "---\n",
      "['islamic']\n",
      "['islam']\n",
      "---\n",
      "---\n",
      "['when', 'too', 'much', 'water', 'is', 'drawn', 'into', 'the', 'bowels']\n",
      "['s', 'when', 'too', 'much', 'water', 'is', 'drawn', 'into', 'the', 'bowels']\n",
      "---\n",
      "---\n",
      "['fifteen']\n",
      "['15']\n",
      "---\n",
      "---\n",
      "['seventh']\n",
      "['7']\n",
      "---\n",
      "---\n",
      "['southern']\n",
      "['corresponded', 'to', 'the', 'greek', 'world', 'until', 'the', 'creation', 'of', 'the', 'greek', 'state', 'in', '183']\n",
      "---\n",
      "---\n",
      "['freedom']\n",
      "['myanmar', 'improved', 'yet', 'again', ',', 'receiving', 'a', 'score', 'of', 'five', 'in', 'civil', 'liberties', 'and', 'a', 'six', 'in', 'political', 'freedom']\n",
      "---\n",
      "---\n",
      "['southeastward']\n",
      "['southeast']\n",
      "---\n",
      "---\n",
      "['evolutionary']\n",
      "['evolution']\n",
      "---\n",
      "---\n",
      "['march', '2006', ',', 'the', 'foundation', 'announced', 'a', 'us', '$', '5', 'million', 'grant', 'for', 'the', 'international', 'justice', 'mission', '(', 'ijm', ')']\n",
      "['n', 'march', '2006', ',', 'the', 'foundation', 'announced', 'a', 'us', '$', '5', 'million', 'grant', 'for', 'the', 'international', 'justice', 'mission', '(', 'ijm', ')']\n",
      "---\n",
      "---\n",
      "['typically', 'discarded']\n",
      "['s', 'typically', 'discarded']\n",
      "---\n",
      "---\n",
      "['fourth']\n",
      "['four']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['opening']\n",
      "['open']\n",
      "---\n",
      "---\n",
      "['roberson']\n",
      "['split', 'with', 'luckett', 'and', 'rober']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "['downplayed']\n",
      "['downplay']\n",
      "---\n",
      "---\n",
      "['maintained']\n",
      "['generally', 'maintain']\n",
      "---\n",
      "---\n",
      "['soviet']\n",
      "['6']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['seven']\n",
      "['7']\n",
      "---\n",
      "---\n",
      "['sixth']\n",
      "['six']\n",
      "---\n",
      "---\n",
      "['southwestern']\n",
      "['southwest']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['on']\n",
      "['one']\n",
      "---\n",
      "---\n",
      "['european']\n",
      "['europe']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['not']\n",
      "['no']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['is']\n",
      "['i']\n",
      "---\n",
      "---\n",
      "['school']\n",
      "['privately', 'funded', 'english', 'language', 'schoo']\n",
      "---\n",
      "---\n",
      "['one']\n",
      "['1']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['western']\n",
      "['west']\n",
      "---\n",
      "---\n",
      "['fifteenth']\n",
      "['15']\n",
      "---\n",
      "---\n",
      "['businesses']\n",
      "['the', 'company', \"'\", 's', 'mainstay', 'business']\n",
      "---\n",
      "---\n",
      "['indirectly']\n",
      "['indirect']\n",
      "---\n",
      "---\n",
      "['in']\n",
      "['9']\n",
      "---\n",
      "---\n",
      "['had', 'become', '\"', 'a', 'derelict', 'open', 'to', 'the', 'occupancy', 'of', 'every', 'enemy', ',', 'civilized', 'or', 'savage']\n",
      "['orida', 'had', 'become', '\"', 'a', 'derelict', 'open', 'to', 'the', 'occupancy', 'of', 'every', 'enemy', ',', 'civilized', 'or', 'savage']\n",
      "---\n",
      "---\n",
      "['you']\n",
      "['74']\n",
      "---\n",
      "---\n",
      "['reforms']\n",
      "['refor']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['and']\n",
      "['end']\n",
      "---\n",
      "---\n",
      "['nine']\n",
      "['9']\n",
      "---\n",
      "---\n",
      "['general']\n",
      "['ge']\n",
      "---\n",
      "---\n",
      "['speaking']\n",
      "['speak']\n",
      "---\n",
      "---\n",
      "['one']\n",
      "['21']\n",
      "---\n",
      "---\n",
      "['european']\n",
      "['europe']\n",
      "---\n",
      "---\n",
      "['sixth']\n",
      "['six']\n",
      "---\n",
      "---\n",
      "['independence']\n",
      "['february', '5', ',', '1862', '.', 'between', 'january', '7', ',', '182']\n",
      "---\n",
      "---\n",
      "['germanic']\n",
      "['german']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['external', 'force', 'which', 'the', 'gymnasts', 'have', 'to', 'overcome', 'with', 'their', 'muscle', 'force', 'and', 'has', 'an', 'impact', 'on', 'the', 'gymnasts', 'linear', 'and', 'angular', 'momentum']\n",
      "['s', 'external', 'force', 'which', 'the', 'gymnasts', 'have', 'to', 'overcome', 'with', 'their', 'muscle', 'force', 'and', 'has', 'an', 'impact', 'on', 'the', 'gymnasts', 'linear', 'and', 'angular', 'momentum']\n",
      "---\n",
      "---\n",
      "['indirectly']\n",
      "['indirect']\n",
      "---\n",
      "---\n",
      "['the']\n",
      "['m', 'and', 'e']\n",
      "---\n",
      "---\n",
      "['rome']\n",
      "['battle', 'of', 'the', 'teutoburg', 'forest', 'r']\n",
      "---\n",
      "---\n",
      "['one']\n",
      "['1']\n",
      "---\n",
      "---\n",
      "['european']\n",
      "['europe']\n",
      "---\n",
      "---\n",
      "['several']\n",
      "['75']\n",
      "---\n",
      "---\n",
      "['china']\n",
      "['ch']\n",
      "---\n",
      "---\n",
      "['not']\n",
      "['no']\n",
      "---\n",
      "---\n",
      "['fearlessness']\n",
      "['fearless']\n",
      "---\n",
      "---\n",
      "['eton']\n",
      "['19']\n",
      "---\n",
      "---\n",
      "['.', 'men', 'did', 'not', 'show', 'any', 'sexual', 'arousal', 'to', 'non', '-', 'human', 'visual', 'stimuli', ',']\n",
      "['x', '.', 'men', 'did', 'not', 'show', 'any', 'sexual', 'arousal', 'to', 'non', '-', 'human', 'visual', 'stimuli', ',']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['four']\n",
      "['4']\n",
      "---\n",
      "---\n",
      "['sixth']\n",
      "['six']\n",
      "---\n",
      "---\n",
      "['have']\n",
      "['5']\n",
      "---\n",
      "---\n",
      "['finally']\n",
      "['final']\n",
      "---\n",
      "---\n",
      "['three']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['in']\n",
      "['n']\n",
      "---\n",
      "---\n",
      "['it']\n",
      "['8']\n",
      "---\n",
      "---\n",
      "['up']\n",
      "['some', 'people', 'with', 'asthma', 'rarely', 'experience', 'symptoms', ',', 'u']\n",
      "---\n",
      "---\n",
      "['etonians']\n",
      "['eton']\n",
      "---\n",
      "---\n",
      "['evolutionary']\n",
      "['evolution']\n",
      "---\n",
      "---\n",
      "['are']\n",
      "['red']\n",
      "---\n",
      "---\n",
      "['rise']\n",
      "['yptian', 'se']\n",
      "---\n",
      "---\n",
      "['six']\n",
      "['6']\n",
      "---\n",
      "---\n",
      "['fifteenth']\n",
      "['15']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['seventh']\n",
      "['7']\n",
      "---\n",
      "---\n",
      "['for']\n",
      "['four']\n",
      "---\n",
      "---\n",
      "['hairdo']\n",
      "['hair']\n",
      "---\n",
      "---\n",
      "['largest']\n",
      "['large']\n",
      "---\n",
      "---\n",
      "['two']\n",
      "['2']\n",
      "---\n",
      "---\n",
      "['wintertime']\n",
      "['winter']\n",
      "---\n",
      "---\n",
      "['the']\n",
      "['3']\n",
      "---\n",
      "---\n",
      "['characteristic']\n",
      "['\"', 'while', 'the', 'interstellar', 'absorbing', 'medium', 'may', 'be', 'simply', 'the', 'ether', ',', '[', 'it', ']', 'is', 'characteris']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "really_discarded_dict = dict()\n",
    "for d in discarded_dict:\n",
    "    qaID = d\n",
    "    paraID, q_words, question, a_words, answer = discarded_dict[qaID]\n",
    "    para_words = para_dict[paraID]\n",
    "    print(\"---\")\n",
    "    try:\n",
    "        i, j = find_sub_list(a_words, para_words)\n",
    "        print(para_words[i:j+1])\n",
    "        print(a_words)\n",
    "    except ValueError:\n",
    "        print(qaID)\n",
    "        really_discarded_dict[qaID] = paraID, q_words, question, a_words, answer\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "really_discarded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sub_list([\"hey\", \"yolo\"], [\"1\", \"hey\", \"yolo\", \"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import difflib\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "def find_exact_sub_list(sublst, lst):\n",
    "    \"\"\"Given a list and a sublist, find the starting and ending indices of the sublist in the list.\"\"\"\n",
    "    for index in (i for i, e in enumerate(lst) if e == sublst[0]): #if list_word == sublist[0]\n",
    "        if lst[index:index+len(sublst)] == sublst:\n",
    "            return index, index + len(sublst) - 1\n",
    "    raise ValueError(\"no exact match found between sublist and list!\")\n",
    "    \n",
    "def find_sub_list(sublst, lst):\n",
    "    try:\n",
    "        return find_exact_sub_list(sublst, lst)\n",
    "    except:\n",
    "        pass\n",
    "    if len(sublst) > 1:\n",
    "        try:\n",
    "            return find_sub_list(sublst[1:], lst)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            return find_sub_list(sublst[1:], lst)\n",
    "        except:\n",
    "            pass\n",
    "    elif len(sublst) == 1:\n",
    "        word = sublst[0]\n",
    "        if bool(re.search(r'\\d', word)): #if word contains a number\n",
    "            try:\n",
    "                number_word = p.number_to_words(word)\n",
    "                return find_sub_list([number_word], lst)\n",
    "            except:\n",
    "                pass\n",
    "        try: #find closest word in paragraph and choose that\n",
    "            idx = np.argmax([difflib.SequenceMatcher(None, word, x).ratio() for x in lst])\n",
    "            return (idx, idx)\n",
    "            #similarities = [difflib.SequenceMatcher(None, word, x).ratio() for x in lst]\n",
    "            #if max(similarities) > 0.4:\n",
    "            #    idx = np.argmax(similarities)\n",
    "            #    return (idx, idx)\n",
    "        except:\n",
    "            pass\n",
    "    raise ValueError(\"approximate match between sublist and list not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sublst = ['t', 'parks', ',', 'schools', ',', 'public', 'buildings', ',', 'proper', 'roads', 'and', 'the', 'other', 'amenities', 'that', 'characterise', 'a', 'modern', 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['the', 'so', '-', 'called', '\"', 'sack', 'of', 'palermo', '\"', 'is', 'one', 'of', 'the', 'major', 'visible', 'faces', 'of', 'the', 'problem', '.', 'the', 'term', 'is', 'used', 'to', 'indicate', 'the', 'speculative', 'building', 'practices', 'that', 'have', 'filled', 'the', 'city', 'with', 'poor', 'buildings', '.', 'the', 'reduced', 'importance', 'of', 'agriculture', 'in', 'the', 'sicilian', 'economy', 'has', 'led', 'to', 'a', 'massive', 'migration', 'to', 'the', 'cities', ',', 'especially', 'palermo', ',', 'which', 'swelled', 'in', 'size', ',', 'leading', 'to', 'rapid', 'expansion', 'towards', 'the', 'north', '.', 'the', 'regulatory', 'plans', 'for', 'expansion', 'was', 'largely', 'ignored', 'in', 'the', 'boom', '.', 'new', 'parts', 'of', 'town', 'appeared', 'almost', 'out', 'of', 'nowhere', ',', 'but', 'without', 'parks', ',', 'schools', ',', 'public', 'buildings', ',', 'proper', 'roads', 'and', 'the', 'other', 'amenities', 'that', 'characterise', 'a', 'modern', 'city', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_approx_sub_list(sublst, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.number_to_words(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 100\n",
    "batch_size = 10\n",
    "rnn_size = 50\n",
    "W_inputs = tf.constant(np.random.random((rnn_size, rnn_size)), dtype=\"float32\")\n",
    "W_pointerRNN = tf.constant(np.random.random((rnn_size, rnn_size)), dtype=\"float32\")\n",
    "v = tf.constant(np.random.random((rnn_size, 1)), dtype=\"float32\")\n",
    "W_inputs_tiled = tf.tile(tf.expand_dims(W_inputs, 0), [batch_size, 1, 1])\n",
    "#W_pointerRNN_tiled = tf.tile(tf.expand_dims(W_pointerRNN, 0), [batch_size, 1, 1])\n",
    "v_tiled = tf.tile(tf.expand_dims(v, 0), [batch_size, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((batch_size, max_seq_length, rnn_size)), dtype=\"float32\")\n",
    "def compute_lengths(inputs):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(inputs), reduction_indices=2))\n",
    "    lengths = tf.reduce_sum(used, reduction_indices=1)\n",
    "    lengths = tf.cast(lengths, tf.int32) #lengths must be integers\n",
    "    return lengths\n",
    "seq_lengths = compute_lengths(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: use attention-pooling over the question representation for the initialize hidden vector of pointer network\n",
    "def loop_fn(time, prev_output, prev_state, prev_loop_state):\n",
    "    print('start loop', time)\n",
    "    next_output = prev_output\n",
    "    if prev_output is None:\n",
    "        next_state = cell.zero_state(batch_size, tf.float32)\n",
    "    else:\n",
    "        next_state = prev_state\n",
    "    next_loop_state = None\n",
    "    def get_next_input():\n",
    "        print(\"computing logits\")\n",
    "        print(\"prev_output\", prev_output)\n",
    "        if prev_output is None:\n",
    "            logits = tf.matmul(tf.tanh(tf.matmul(inputs, W_inputs_tiled)), v_tiled) #batch_size x seq_length x rnn_size\n",
    "        else:\n",
    "            print(\"i have prev output now\")\n",
    "            logits = tf.matmul(\n",
    "                             tf.tanh(tf.matmul(inputs, W_inputs_tiled) + \n",
    "                                     tf.tile(tf.expand_dims(tf.matmul(prev_output, W_pointerRNN), 1), [1, max_seq_length, 1]))\n",
    "                             , v_tiled) #batch_size x seq_length x rnn_size\n",
    "        print(\"computing probs\")\n",
    "        predicted_probs = tf.nn.softmax(logits, dim=1) #a\n",
    "        print(\"predicted_probs\")\n",
    "        weighted_input = tf.reduce_sum(tf.multiply(predicted_probs, inputs), axis=1) #c #batch_size x rnn_size\n",
    "        print(\"returning weighted_input\")\n",
    "        return weighted_input #weighted input is next input\n",
    "    print(\"1\")\n",
    "    elements_finished = (time >= seq_lengths) #this operation produces boolean tensor of [batch_size] defining if corresponding sequence has ended\n",
    "    print(\"2\")\n",
    "    finished = tf.reduce_all(elements_finished) #AND operation over all batches. True if all batches finished.\n",
    "    time += 1\n",
    "    print(\"3\")\n",
    "    next_input = tf.cond(finished, lambda: tf.zeros([batch_size, rnn_size], dtype=tf.float32), get_next_input)\n",
    "    print(\"4\")\n",
    "    return elements_finished, next_input, next_state, next_output, next_loop_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
    "    cell = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "    outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "    outputs = outputs_ta.stack()\n",
    "    #predicted_idx = tf.argmax(predicted_probs) #p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((batch_size, max_seq_length, rnn_size)), dtype=\"float32\")\n",
    "inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_seq_length)\n",
    "inputs_ta = inputs_ta.unstack(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ta.size().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ta.read(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((max_seq_length, batch_size, rnn_size)), dtype=\"float32\")\n",
    "inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_seq_length)\n",
    "inputs_ta = inputs_ta.unstack(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ta.read(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.LSTMCell(rnn_size, reuse=True)\n",
    "outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "outputs = outputs_ta.stack()\n",
    "outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "outputs = outputs_ta.stack()\n",
    "predicted_idx = tf.argmax(self.predicted_probs) #p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: use attention-pooling over the question representation for the initialize hidden vector of pointer network\n",
    "def loop_fn(time, prev_output, prev_state, prev_loop_state):\n",
    "    print('start loop')\n",
    "    next_output = prev_output\n",
    "    if prev_output is None:\n",
    "        next_cell_state = cell.zero_state(batch_size, tf.float32)\n",
    "    else:\n",
    "        next_cell_state = prev_state\n",
    "    next_loop_state = None\n",
    "    def get_next_input():\n",
    "        print(\"computing logits\")\n",
    "        print(inputs_ta.read(time))\n",
    "        print(prev_output)\n",
    "        if prev_output is None:\n",
    "            logits = tf.matmul(v, tf.tanh(tf.matmul(inputs_ta.read(time), W_inputs)))\n",
    "        else:\n",
    "            logits = tf.matmul(tf.tanh(tf.matmul(inputs_ta.read(time), W_inputs) + tf.matmul(prev_output, W_pointerRNN)), v) #s #at each step network has access to all paragraph inputs, plus the previous RNN outputs\n",
    "        print(\"computing probs\")\n",
    "        predicted_probs = tf.nn.softmax(logits) #a\n",
    "        print(\"computing weighted_input\")\n",
    "        weighted_input = tf.reduce_sum(tf.multiply(predicted_probs, inputs)) #c\n",
    "        return weighted_input #weighted input is next input\n",
    "    print(\"1\")\n",
    "    elements_finished = (time >= seq_lengths) #this operation produces boolean tensor of [batch_size] defining if corresponding sequence has ended\n",
    "    print(\"2\")\n",
    "    finished = tf.reduce_all(elements_finished) #AND operation over all batches. True if all batches finished.\n",
    "    time += 1\n",
    "    print(\"3\")\n",
    "    next_input = tf.cond(finished, lambda: tf.zeros([batch_size, rnn_size], dtype=tf.float32), get_next_input)\n",
    "    print(\"4\")\n",
    "    return elements_finished, next_input, next_state, next_output, next_loop_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((batch_size, max_seq_length, rnn_size)))\n",
    "def compute_lengths(inputs):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(inputs), reduction_indices=2))\n",
    "    lengths = tf.reduce_sum(used, reduction_indices=1)\n",
    "    lengths = tf.cast(lengths, tf.int32) #lengths must be integers\n",
    "    return lengths\n",
    "seq_lengths = compute_lengths(inputs)\n",
    "seq_lengths.eval()\n",
    "def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "    print(\"start loop\")\n",
    "    emit_output = cell_output  # == None for time == 0\n",
    "    if cell_output is None:  # time == 0\n",
    "        next_cell_state = cell.zero_state(batch_size, tf.float32)\n",
    "    else:\n",
    "        next_cell_state = cell_state\n",
    "    print(\"1\")\n",
    "    elements_finished = (time >= seq_lengths)\n",
    "    print(\"2\")\n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "    print(\"3\")\n",
    "    next_input = tf.cond(\n",
    "        finished,\n",
    "        lambda: tf.zeros([batch_size, rnn_size], dtype=tf.float32),\n",
    "        lambda: inputs_ta.read(time))\n",
    "    print(\"4\")\n",
    "    next_loop_state = None\n",
    "    print(\"5\")\n",
    "    print(\"elements_finished\", elements_finished)\n",
    "    print(\"next_input\", next_input)\n",
    "    print(\"next_cell_state\", next_cell_state)\n",
    "    print(\"next_loop_state\", next_loop_state)\n",
    "    return elements_finished, next_input, next_cell_state, emit_output, next_loop_state\n",
    "\n",
    "max_seq_length = 100\n",
    "batch_size = 10\n",
    "rnn_size = 50\n",
    "W_inputs = tf.constant(np.random.random((rnn_size, rnn_size)))\n",
    "W_pointerRNN = tf.constant(np.random.random((rnn_size, rnn_size)))\n",
    "v = tf.constant(np.random.random((1, rnn_size)))\n",
    "inputs = tf.constant(np.random.random((max_seq_length, batch_size, rnn_size)))\n",
    "inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_seq_length)\n",
    "inputs_ta = inputs_ta.unstack(inputs)\n",
    "cell = tf.contrib.rnn.LSTMCell(rnn_size, reuse=True)\n",
    "outputs_ta, final_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "outputs = outputs_ta.stack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
